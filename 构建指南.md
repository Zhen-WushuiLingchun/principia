# The Principia (Alpha) - 本地构建指南

欢迎来到 **The Principia**，这是一个将文本和手写内容转化为 TeX 和 markdown 格式，并同时生成交互式模拟的生成式引擎。

本指南将帮助您在本地搭建该项目。

## 前置要求

在开始之前，请确保您已安装以下软件：

1.  **Node.js** (v18 或更高版本) & **npm**: [点击下载](https://nodejs.org/)
2.  **Python** (v3.8 或更高版本) & **pip**: [点击下载](https://www.python.org/)
3.  **Git**: [点击下载](https://git-scm.com/)

## 项目结构

~~~text
principia_alpha/
├── app.py              # Flask 后端 (API 代理 & 业务逻辑)
├── requirements.txt    # Python 依赖项
├── principia/          # 前端 (React + Vite)
│   ├── src/            # 源代码
│   ├── public/         # 静态资源
│   ├── package.json    # Node 依赖项
│   └── ...
└── 构建指南.md           # 本文件
~~~

## 步骤 1：后端设置 (Python)

后端是一个 Flask 应用程序，负责处理对 LLM 提供商（DeepSeek, OpenAI, Gemini）的 API 请求，并服务于前端构建文件。

1.  在 `principia_alpha` 文件夹中打开终端。
2.  创建一个虚拟环境（可选但推荐）：
    ~~~bash
    python -m venv venv
    # Windows 系统:
    .\venv\Scripts\activate
    # Mac/Linux 系统:
    source venv/bin/activate
    ~~~
3.  安装依赖项：
    ~~~bash
    pip install -r requirements.txt
    ~~~
4.  启动后端服务器：
    ~~~bash
    python app.py
    ~~~
    您应该会看到提示：`The Principia Backend Running on Port 8000`

5.  **实际生产环境运行**

    在实际生产环境部署时，关闭 Debug 模式非常重要。

    在 `app.py` 文件的最后一行，将 `debug=True` 修改为 `debug=False` 即可：

    ~~~python
    # 修改前
    app.run(port=PORT, debug=True, use_reloader=False)

    # 修改后
    app.run(port=PORT, debug=False, use_reloader=False)
    ~~~

    **为什么需要关闭？**
    1.  **安全性**：Debug 模式会在报错时直接在浏览器中显示详细的堆栈跟踪（Stack Trace），可能泄露服务器路径、代码结构等敏感信息。
    2.  **性能**：Debug 模式会开启额外的调试钩子，影响性能。
    3.  **稳定性**：Debug 模式下的某些行为（如自动重载）不适合生产环境。

    **更专业的建议：**
    如果在真正的生产服务器（如 AWS, Linux VPS）上运行，通常不直接使用 `python app.py`（这是 Flask 自带的开发服务器），而是配合 Gunicorn 或 Waitress 等 WSGI 服务器来运行：

    ~~~bash
    # 安装 waitress (Windows/Linux 通用，简单易用)
    pip install waitress

    # 启动命令 (替代 python app.py)
    waitress-serve --port=8000 app:app
    ~~~
    这样即便是 `app.py` 里写了 `debug=True`，Waitress 也会忽略它，以生产模式运行。

## 步骤 2：前端设置 (React + Vite)

前端是一个现代化的 React 应用程序。

1.  打开一个**新**的终端窗口。
2.  进入 `principia` 文件夹：
    ~~~bash
    cd principia_alpha/principia
    ~~~
3.  安装依赖项：
    ~~~bash
    npm install
    ~~~
4.  构建生产环境前端：
    ~~~bash
    npm run build
    ~~~
    *注意：后端 `app.py` 已配置为服务 `principia/dist` 目录下的静态文件，该目录由通过此命令创建。*

## 步骤 3：运行应用程序

一旦后端正在运行且前端构建完成：

1.  打开浏览器并访问：`http://localhost:8000`
2.  您应该能看到 The Principia 的界面。

## 步骤 4：配置（重要！）
*（批注：这时候就进入使用阶段了，你得在网页端打开了）*

The Principia 依赖于外部 AI 模型。您需要在应用程序设置中配置您的 API 密钥。

1.  点击右上角的 **设置** 图标（齿轮状）。
2.  **Reasoning API (推理/解释)**:
    * 推荐：**DeepSeek** 或 **OpenAI**。
    * Base URL (基地址): `https://api.deepseek.com/v1` (适用于 DeepSeek)
    * API Key: 您的 API 密钥
    * Model (模型): `deepseek-chat`
3.  **Multimodal API (多模态/视觉 & 模拟)**:
    * 推荐：**Gemini** (Google) 或兼容的 OpenAI Vision 模型。
    * Base URL (基地址): `https://generativelanguage.googleapis.com/v1beta/openai/` (适用于 Gemini)
    * API Key: 您的 API 密钥
    * Model (模型): `gemini-2.0-flash-exp` (或类似模型)
4.  点击 **Save Configuration** (保存配置)。

## 疑难解答

* **Port 8000 already in use (端口 8000 已被占用)**: 编辑 `app.py` 并将 `PORT = 8000` 更改为其他数字。
* **API Errors (API 错误)**: 检查浏览器控制台 (按 F12) 和运行 `app.py` 的终端以获取错误详情。确保您的 API 密钥有效且有足够的配额。
* **Frontend changes not showing (前端更改未显示)**: 如果您修改了 `principia/src` 中的代码，必须再次运行 `npm run build` 以更新服务的文件。如果需要进行带热重载的开发，您可以在 `principia` 文件夹中运行 `npm run dev`，但此时需通过端口 5173 访问（可能需要调整 CORS/代理设置）。

## 开发模式

如果您想利用热重载功能开发前端：

1.  保持 `python app.py` 在端口 8000 上运行。
2.  在 `principia/vite.config.ts` 中，确保代理 (proxy) 设置指向 `http://localhost:8000`。
3.  在 `principia` 文件夹中运行 `npm run dev`。
4.  通过 `http://localhost:5173` 访问应用。